{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-Powered Audio Transcription & Note Generation Bot\n",
    "\n",
    "This notebook creates an AI bot that can:\n",
    "- Record or accept uploaded audio files\n",
    "- Transcribe audio using OpenAI Whisper\n",
    "- Generate detailed notes and summaries using LLM\n",
    "- Provide an intuitive Gradio interface\n",
    "\n",
    "## Features:\n",
    "- **Audio Input**: Record live or upload files\n",
    "- **Transcription**: High-quality speech-to-text\n",
    "- **Smart Notes**: AI-generated summaries and topic breakdowns\n",
    "- **User-Friendly UI**: Clean Gradio interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports\n",
    "\n",
    "First, let's install and import all required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run this first)\n",
    "!pip install gradio openai-whisper transformers torch torchaudio soundfile librosa numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import gradio as gr\n",
    "import whisper\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Audio processing\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "# LLM and text processing\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import re\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üî• PyTorch version: {torch.__version__}\")\n",
    "print(f\"üéµ Whisper available: {whisper.__version__ if hasattr(whisper, '__version__') else 'Yes'}\")\n",
    "print(f\"üé® Gradio version: {gr.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Audio Recording & Upload Functions\n",
    "\n",
    "These functions handle audio input from recording or file upload:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_file(audio_file):\n",
    "    \"\"\"\n",
    "    Process uploaded audio file and prepare it for transcription.\n",
    "    \n",
    "    Args:\n",
    "        audio_file: Path to audio file or tuple (sample_rate, audio_data)\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to processed audio file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if audio_file is None:\n",
    "            return None\n",
    "        \n",
    "        # Handle different input types\n",
    "        if isinstance(audio_file, tuple):\n",
    "            # From microphone recording (sample_rate, audio_data)\n",
    "            sample_rate, audio_data = audio_file\n",
    "            \n",
    "            # Create temporary file\n",
    "            with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as tmp_file:\n",
    "                sf.write(tmp_file.name, audio_data, sample_rate)\n",
    "                return tmp_file.name\n",
    "        \n",
    "        elif isinstance(audio_file, str):\n",
    "            # File path from upload\n",
    "            return audio_file\n",
    "        \n",
    "        else:\n",
    "            # Gradio file object\n",
    "            return audio_file.name if hasattr(audio_file, 'name') else str(audio_file)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing audio file: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def get_audio_info(audio_path):\n",
    "    \"\"\"\n",
    "    Get information about the audio file.\n",
    "    \n",
    "    Args:\n",
    "        audio_path (str): Path to audio file\n",
    "    \n",
    "    Returns:\n",
    "        dict: Audio information\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not audio_path or not os.path.exists(audio_path):\n",
    "            return {\"error\": \"Audio file not found\"}\n",
    "        \n",
    "        # Load audio to get info\n",
    "        audio_data, sample_rate = librosa.load(audio_path, sr=None)\n",
    "        duration = len(audio_data) / sample_rate\n",
    "        \n",
    "        return {\n",
    "            \"duration\": f\"{duration:.2f} seconds\",\n",
    "            \"sample_rate\": f\"{sample_rate} Hz\",\n",
    "            \"channels\": \"Mono\",\n",
    "            \"file_size\": f\"{os.path.getsize(audio_path) / 1024:.1f} KB\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Could not analyze audio: {str(e)}\"}\n",
    "\n",
    "print(\"‚úÖ Audio processing functions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Transcription Function\n",
    "\n",
    "Using OpenAI Whisper for high-quality speech-to-text transcription:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Whisper model (using base model for balance of speed and accuracy)\n",
    "print(\"üîÑ Loading Whisper model...\")\n",
    "whisper_model = whisper.load_model(\"base\")\n",
    "print(\"‚úÖ Whisper model loaded successfully!\")\n",
    "\n",
    "def transcribe_audio(audio_file, language=\"auto\"):\n",
    "    \"\"\"\n",
    "    Transcribe audio file using OpenAI Whisper.\n",
    "    \n",
    "    Args:\n",
    "        audio_file: Audio file path or Gradio audio input\n",
    "        language (str): Language code or 'auto' for auto-detection\n",
    "    \n",
    "    Returns:\n",
    "        dict: Transcription results with text, language, and confidence\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not audio_file:\n",
    "            return {\n",
    "                \"text\": \"\",\n",
    "                \"language\": \"unknown\",\n",
    "                \"status\": \"‚ùå No audio file provided\"\n",
    "            }\n",
    "        \n",
    "        # Process the audio file\n",
    "        audio_path = process_audio_file(audio_file)\n",
    "        if not audio_path:\n",
    "            return {\n",
    "                \"text\": \"\",\n",
    "                \"language\": \"unknown\",\n",
    "                \"status\": \"‚ùå Could not process audio file\"\n",
    "            }\n",
    "        \n",
    "        print(f\"üîÑ Transcribing audio: {os.path.basename(audio_path)}\")\n",
    "        \n",
    "        # Transcribe using Whisper\n",
    "        if language == \"auto\":\n",
    "            result = whisper_model.transcribe(audio_path)\n",
    "        else:\n",
    "            result = whisper_model.transcribe(audio_path, language=language)\n",
    "        \n",
    "        # Extract results\n",
    "        transcribed_text = result[\"text\"].strip()\n",
    "        detected_language = result.get(\"language\", \"unknown\")\n",
    "        \n",
    "        # Clean up temporary file if created\n",
    "        if audio_path != audio_file and os.path.exists(audio_path):\n",
    "            try:\n",
    "                os.unlink(audio_path)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if not transcribed_text:\n",
    "            return {\n",
    "                \"text\": \"\",\n",
    "                \"language\": detected_language,\n",
    "                \"status\": \"‚ö†Ô∏è No speech detected in audio\"\n",
    "            }\n",
    "        \n",
    "        print(f\"‚úÖ Transcription completed! Language: {detected_language}\")\n",
    "        \n",
    "        return {\n",
    "            \"text\": transcribed_text,\n",
    "            \"language\": detected_language,\n",
    "            \"status\": f\"‚úÖ Transcription successful ({detected_language})\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Transcription error: {str(e)}\")\n",
    "        return {\n",
    "            \"text\": \"\",\n",
    "            \"language\": \"unknown\",\n",
    "            \"status\": f\"‚ùå Transcription failed: {str(e)}\"\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Transcription function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LLM Summary & Note Generation Functions\n",
    "\n",
    "Using HuggingFace transformers for text summarization and note generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load summarization model\n",
    "print(\"üîÑ Loading summarization model...\")\n",
    "try:\n",
    "    # Using BART for summarization (good balance of quality and speed)\n",
    "    summarizer = pipeline(\n",
    "        \"summarization\", \n",
    "        model=\"facebook/bart-large-cnn\",\n",
    "        device=0 if torch.cuda.is_available() else -1\n",
    "    )\n",
    "    print(\"‚úÖ BART summarization model loaded!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not load BART model, using fallback: {e}\")\n",
    "    # Fallback to a smaller model\n",
    "    summarizer = pipeline(\n",
    "        \"summarization\", \n",
    "        model=\"sshleifer/distilbart-cnn-12-6\",\n",
    "        device=0 if torch.cuda.is_available() else -1\n",
    "    )\n",
    "    print(\"‚úÖ DistilBART summarization model loaded!\")\n",
    "\n",
    "def chunk_text(text, max_chunk_length=1000):\n",
    "    \"\"\"\n",
    "    Split text into chunks for processing by the summarization model.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text\n",
    "        max_chunk_length (int): Maximum length per chunk\n",
    "    \n",
    "    Returns:\n",
    "        list: List of text chunks\n",
    "    \"\"\"\n",
    "    # Split by sentences first\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        if len(current_chunk + sentence) <= max_chunk_length:\n",
    "            current_chunk += sentence + \" \"\n",
    "        else:\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence + \" \"\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def generate_summary(text):\n",
    "    \"\"\"\n",
    "    Generate a concise summary of the transcribed text.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input transcribed text\n",
    "    \n",
    "    Returns:\n",
    "        str: Generated summary\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not text or len(text.strip()) < 50:\n",
    "            return \"‚ö†Ô∏è Text too short to summarize effectively.\"\n",
    "        \n",
    "        print(\"üîÑ Generating summary...\")\n",
    "        \n",
    "        # Handle long texts by chunking\n",
    "        if len(text) > 1000:\n",
    "            chunks = chunk_text(text, 900)\n",
    "            summaries = []\n",
    "            \n",
    "            for i, chunk in enumerate(chunks):\n",
    "                print(f\"üìù Summarizing chunk {i+1}/{len(chunks)}\")\n",
    "                try:\n",
    "                    summary = summarizer(\n",
    "                        chunk, \n",
    "                        max_length=130, \n",
    "                        min_length=30, \n",
    "                        do_sample=False\n",
    "                    )[0]['summary_text']\n",
    "                    summaries.append(summary)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Error summarizing chunk {i+1}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            # Combine chunk summaries\n",
    "            combined_summary = \" \".join(summaries)\n",
    "            \n",
    "            # If combined summary is still long, summarize it again\n",
    "            if len(combined_summary) > 800:\n",
    "                final_summary = summarizer(\n",
    "                    combined_summary, \n",
    "                    max_length=200, \n",
    "                    min_length=50, \n",
    "                    do_sample=False\n",
    "                )[0]['summary_text']\n",
    "                return final_summary\n",
    "            else:\n",
    "                return combined_summary\n",
    "        \n",
    "        else:\n",
    "            # Short text, summarize directly\n",
    "            summary = summarizer(\n",
    "                text, \n",
    "                max_length=150, \n",
    "                min_length=30, \n",
    "                do_sample=False\n",
    "            )[0]['summary_text']\n",
    "            return summary\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Summary generation error: {str(e)}\")\n",
    "        return f\"‚ùå Could not generate summary: {str(e)}\"\n",
    "\n",
    "def extract_topics_and_notes(text):\n",
    "    \"\"\"\n",
    "    Extract key topics and generate structured notes from the text.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input transcribed text\n",
    "    \n",
    "    Returns:\n",
    "        str: Formatted topic breakdown and notes\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not text or len(text.strip()) < 50:\n",
    "            return \"‚ö†Ô∏è Text too short for topic extraction.\"\n",
    "        \n",
    "        print(\"üîÑ Extracting topics and generating notes...\")\n",
    "        \n",
    "        # Simple topic extraction using keywords and sentence analysis\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "        \n",
    "        # Extract potential topics (nouns and important phrases)\n",
    "        import collections\n",
    "        words = re.findall(r'\\b[A-Z][a-z]+\\b|\\b[a-z]{4,}\\b', text)\n",
    "        word_freq = collections.Counter(words)\n",
    "        \n",
    "        # Get most common meaningful words as topics\n",
    "        stop_words = {'this', 'that', 'with', 'have', 'will', 'from', 'they', 'been', 'were', 'said', 'each', 'which', 'their', 'time', 'about'}\n",
    "        topics = [word for word, freq in word_freq.most_common(10) \n",
    "                 if word.lower() not in stop_words and freq > 1]\n",
    "        \n",
    "        # Create structured notes\n",
    "        notes = \"## üìã Structured Notes\\n\\n\"\n",
    "        \n",
    "        # Key topics section\n",
    "        if topics:\n",
    "            notes += \"### üéØ Key Topics Mentioned:\\n\"\n",
    "            for i, topic in enumerate(topics[:5], 1):\n",
    "                notes += f\"{i}. **{topic.title()}**\\n\"\n",
    "            notes += \"\\n\"\n",
    "        \n",
    "        # Main points section\n",
    "        notes += \"### üí° Main Points:\\n\"\n",
    "        \n",
    "        # Split into logical sections (every 3-4 sentences)\n",
    "        section_size = max(3, len(sentences) // 5)  # Aim for ~5 sections\n",
    "        sections = [sentences[i:i+section_size] for i in range(0, len(sentences), section_size)]\n",
    "        \n",
    "        for i, section in enumerate(sections, 1):\n",
    "            if section:\n",
    "                section_text = \" \".join(section)\n",
    "                if len(section_text.strip()) > 20:  # Only include substantial sections\n",
    "                    # Try to summarize each section\n",
    "                    try:\n",
    "                        if len(section_text) > 100:\n",
    "                            section_summary = summarizer(\n",
    "                                section_text, \n",
    "                                max_length=60, \n",
    "                                min_length=15, \n",
    "                                do_sample=False\n",
    "                            )[0]['summary_text']\n",
    "                        else:\n",
    "                            section_summary = section_text\n",
    "                        \n",
    "                        notes += f\"- **Point {i}:** {section_summary}\\n\"\n",
    "                    except:\n",
    "                        # Fallback to original text if summarization fails\n",
    "                        notes += f\"- **Point {i}:** {section_text[:100]}...\\n\"\n",
    "        \n",
    "        # Add timestamp\n",
    "        notes += f\"\\n---\\n*Notes generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\"\n",
    "        \n",
    "        return notes\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Topic extraction error: {str(e)}\")\n",
    "        return f\"‚ùå Could not extract topics: {str(e)}\"\n",
    "\n",
    "print(\"‚úÖ LLM summary and note generation functions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Main Processing Function\n",
    "\n",
    "Combining all components into a single processing pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_complete(audio_file, language=\"auto\"):\n",
    "    \"\"\"\n",
    "    Complete pipeline: Audio ‚Üí Transcription ‚Üí Summary ‚Üí Notes\n",
    "    \n",
    "    Args:\n",
    "        audio_file: Audio input from Gradio\n",
    "        language (str): Language for transcription\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (transcription, summary, notes, status)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"üöÄ Starting complete audio processing pipeline...\")\n",
    "        \n",
    "        # Step 1: Transcribe audio\n",
    "        transcription_result = transcribe_audio(audio_file, language)\n",
    "        \n",
    "        if not transcription_result[\"text\"]:\n",
    "            return (\n",
    "                \"‚ùå No transcription available\",\n",
    "                \"‚ùå Cannot generate summary without transcription\",\n",
    "                \"‚ùå Cannot generate notes without transcription\",\n",
    "                transcription_result[\"status\"]\n",
    "            )\n",
    "        \n",
    "        transcribed_text = transcription_result[\"text\"]\n",
    "        \n",
    "        # Step 2: Generate summary\n",
    "        print(\"üìù Generating summary...\")\n",
    "        summary = generate_summary(transcribed_text)\n",
    "        \n",
    "        # Step 3: Extract topics and generate notes\n",
    "        print(\"üìã Generating structured notes...\")\n",
    "        notes = extract_topics_and_notes(transcribed_text)\n",
    "        \n",
    "        # Create status message\n",
    "        status = f\"\"\"‚úÖ **Processing Complete!**\n",
    "\n",
    "üìä **Statistics:**\n",
    "- Language detected: {transcription_result['language']}\n",
    "- Transcription length: {len(transcribed_text)} characters\n",
    "- Word count: ~{len(transcribed_text.split())} words\n",
    "- Processing time: {datetime.now().strftime('%H:%M:%S')}\n",
    "\"\"\"\n",
    "        \n",
    "        print(\"üéâ Complete processing finished successfully!\")\n",
    "        \n",
    "        return (\n",
    "            transcribed_text,\n",
    "            summary,\n",
    "            notes,\n",
    "            status\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"‚ùå Processing failed: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return (\n",
    "            error_msg,\n",
    "            error_msg,\n",
    "            error_msg,\n",
    "            error_msg\n",
    "        )\n",
    "\n",
    "print(\"‚úÖ Main processing function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Gradio Interface\n",
    "\n",
    "Creating an intuitive and beautiful user interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gradio_interface():\n",
    "    \"\"\"\n",
    "    Create and configure the Gradio interface.\n",
    "    \n",
    "    Returns:\n",
    "        gr.Interface: Configured Gradio interface\n",
    "    \"\"\"\n",
    "    \n",
    "    # Custom CSS for better styling\n",
    "    custom_css = \"\"\"\n",
    "    .gradio-container {\n",
    "        font-family: 'Arial', sans-serif;\n",
    "        max-width: 1200px;\n",
    "        margin: 0 auto;\n",
    "    }\n",
    "    .output-text {\n",
    "        font-size: 14px;\n",
    "        line-height: 1.6;\n",
    "    }\n",
    "    .status-box {\n",
    "        background-color: #f0f8ff;\n",
    "        border-radius: 8px;\n",
    "        padding: 10px;\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the interface using Blocks for more control\n",
    "    with gr.Blocks(\n",
    "        css=custom_css,\n",
    "        title=\"üé§ AI Audio Transcription & Note Generator\",\n",
    "        theme=gr.themes.Soft()\n",
    "    ) as interface:\n",
    "        \n",
    "        # Header\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            # üé§ AI-Powered Audio Transcription & Note Generator\n",
    "            \n",
    "            Transform your audio recordings into structured notes and summaries using AI!\n",
    "            \n",
    "            **Features:**\n",
    "            - üéôÔ∏è Record audio directly or upload files\n",
    "            - üó£Ô∏è High-quality speech-to-text transcription\n",
    "            - üìù AI-generated summaries and structured notes\n",
    "            - üåç Multi-language support\n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                # Input section\n",
    "                gr.Markdown(\"## üéµ Audio Input\")\n",
    "                \n",
    "                audio_input = gr.Audio(\n",
    "                    label=\"üé§ Record or Upload Audio\",\n",
    "                    type=\"filepath\",\n",
    "                    sources=[\"microphone\", \"upload\"]\n",
    "                )\n",
    "                \n",
    "                language_input = gr.Dropdown(\n",
    "                    choices=[\n",
    "                        (\"Auto-detect\", \"auto\"),\n",
    "                        (\"English\", \"en\"),\n",
    "                        (\"Spanish\", \"es\"),\n",
    "                        (\"French\", \"fr\"),\n",
    "                        (\"German\", \"de\"),\n",
    "                        (\"Italian\", \"it\"),\n",
    "                        (\"Portuguese\", \"pt\"),\n",
    "                        (\"Russian\", \"ru\"),\n",
    "                        (\"Japanese\", \"ja\"),\n",
    "                        (\"Chinese\", \"zh\")\n",
    "                    ],\n",
    "                    value=\"auto\",\n",
    "                    label=\"üåç Language\"\n",
    "                )\n",
    "                \n",
    "                process_btn = gr.Button(\n",
    "                    \"üöÄ Process Audio\", \n",
    "                    variant=\"primary\",\n",
    "                    size=\"lg\"\n",
    "                )\n",
    "                \n",
    "                # Status display\n",
    "                status_output = gr.Markdown(\n",
    "                    \"üìã Ready to process audio...\",\n",
    "                    elem_classes=[\"status-box\"]\n",
    "                )\n",
    "            \n",
    "            with gr.Column(scale=2):\n",
    "                # Output section\n",
    "                gr.Markdown(\"## üìä Results\")\n",
    "                \n",
    "                with gr.Tabs():\n",
    "                    with gr.TabItem(\"üìù Transcription\"):\n",
    "                        transcription_output = gr.Textbox(\n",
    "                            label=\"üó£Ô∏è Transcribed Text\",\n",
    "                            placeholder=\"Transcription will appear here...\",\n",
    "                            lines=10,\n",
    "                            max_lines=15,\n",
    "                            elem_classes=[\"output-text\"]\n",
    "                        )\n",
    "                    \n",
    "                    with gr.TabItem(\"üìã Summary\"):\n",
    "                        summary_output = gr.Textbox(\n",
    "                            label=\"üìã AI-Generated Summary\",\n",
    "                            placeholder=\"Summary will appear here...\",\n",
    "                            lines=8,\n",
    "                            max_lines=12,\n",
    "                            elem_classes=[\"output-text\"]\n",
    "                        )\n",
    "                    \n",
    "                    with gr.TabItem(\"üéØ Structured Notes\"):\n",
    "                        notes_output = gr.Markdown(\n",
    "                            \"Structured notes will appear here...\",\n",
    "                            elem_classes=[\"output-text\"]\n",
    "                        )\n",
    "        \n",
    "        # Example section\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            ---\n",
    "            ## üí° Tips for Best Results:\n",
    "            \n",
    "            - **Audio Quality**: Use clear audio with minimal background noise\n",
    "            - **Duration**: Works best with 30 seconds to 10 minutes of audio\n",
    "            - **Language**: Select the correct language for better accuracy\n",
    "            - **Content**: Structured speech (meetings, lectures) works better than casual conversation\n",
    "            \n",
    "            ## üîß Supported Formats:\n",
    "            WAV, MP3, MP4, M4A, FLAC, and more!\n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        # Connect the processing function\n",
    "        process_btn.click(\n",
    "            fn=process_audio_complete,\n",
    "            inputs=[audio_input, language_input],\n",
    "            outputs=[transcription_output, summary_output, notes_output, status_output],\n",
    "            show_progress=True\n",
    "        )\n",
    "        \n",
    "        # Auto-process when audio is uploaded (optional)\n",
    "        audio_input.change(\n",
    "            fn=lambda audio: \"üéµ Audio uploaded! Click 'Process Audio' to continue.\" if audio else \"üìã Ready to process audio...\",\n",
    "            inputs=[audio_input],\n",
    "            outputs=[status_output]\n",
    "        )\n",
    "    \n",
    "    return interface\n",
    "\n",
    "print(\"‚úÖ Gradio interface function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Demo Launch Cell\n",
    "\n",
    "Launch the complete application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and launch the Gradio interface\n",
    "print(\"üöÄ Launching AI Audio Transcription & Note Generator...\")\n",
    "print(\"üìù This may take a moment to load all models...\")\n",
    "\n",
    "# Create the interface\n",
    "demo = create_gradio_interface()\n",
    "\n",
    "# Launch with configuration\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(\n",
    "        share=True,          # Create public link (set to False for local only)\n",
    "        server_name=\"0.0.0.0\",  # Allow external connections\n",
    "        server_port=7860,    # Port number\n",
    "        show_error=True,     # Show detailed errors\n",
    "        quiet=False          # Show startup logs\n",
    "    )\n",
    "    \n",
    "print(\"üéâ Application launched successfully!\")\n",
    "print(\"üì± Access the app through the provided URL\")\n",
    "print(\"üîÑ The interface will auto-refresh when you make changes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Usage Instructions\n",
    "\n",
    "1. **Run all cells above** to set up the environment and load models\n",
    "2. **Launch the demo** using the cell above\n",
    "3. **Upload or record audio** using the interface\n",
    "4. **Select language** (or use auto-detect)\n",
    "5. **Click 'Process Audio'** to get transcription, summary, and notes\n",
    "\n",
    "## üîß Customization Options\n",
    "\n",
    "- **Change Whisper model**: Modify `whisper.load_model(\"base\")` to use \"tiny\", \"small\", \"medium\", or \"large\"\n",
    "- **Adjust summary length**: Modify `max_length` and `min_length` in summarization functions\n",
    "- **Add more languages**: Extend the language dropdown in the Gradio interface\n",
    "- **Customize UI**: Modify the CSS and layout in the `create_gradio_interface()` function\n",
    "\n",
    "## üìä Model Information\n",
    "\n",
    "- **Transcription**: OpenAI Whisper (base model)\n",
    "- **Summarization**: Facebook BART or DistilBART\n",
    "- **Interface**: Gradio with custom styling\n",
    "\n",
    "---\n",
    "*Built with ‚ù§Ô∏è using open-source AI models*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}